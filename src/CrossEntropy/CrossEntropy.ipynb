{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/simple-vector-incr.cpp\n",
    "\n",
    "#include <chrono>\n",
    "#include <iostream>\n",
    "#include <CL/sycl.hpp>\n",
    "#include <cmath>\n",
    "\n",
    "#define random_float() (rand() / double(RAND_MAX))\n",
    "// 用于生成0~N-1的随机数，用于生成mask\n",
    "#define random_int(N) (int)(rand() / double(RAND_MAX) * N)\n",
    "using namespace std;\n",
    "using namespace sycl;\n",
    "\n",
    "// gpu加速\n",
    "// 返回计算时间\n",
    "// X为输入向量，loss为结果，K为batchsize，M为cXtegory，N为feature,blockSize为分块大小，q为GPU队列\n",
    "double gpu_kernel(const float *X, float *loss, float *Y, int *mask, float *weight,\n",
    "                  int M, int N, int K, int blockSize, sycl::queue &q) {\n",
    "\n",
    "// 下面利用GPU并行算法来计算X[K][M][N]的每个行之和\n",
    "    // row和col对应K和M\n",
    "    auto grid_rows = (K + blockSize - 1) / blockSize * blockSize;\n",
    "    auto grid_cols = (M + blockSize - 1) / blockSize * blockSize;\n",
    "    auto locXl_ndrange = range<2>(blockSize, blockSize);\n",
    "    auto global_ndrange = range<2>(grid_rows, grid_cols);\n",
    "    // 时间\n",
    "    double duration = 0.0f;\n",
    "    //提交工作\n",
    "    auto e = q.submit([&](sycl::handler &h) {\n",
    "        // GPU并行计算\n",
    "        h.parallel_for<class k_name_t>(\n",
    "                sycl::nd_range<2>(global_ndrange, locXl_ndrange), [=](sycl::nd_item<2> index) {\n",
    "                    // row和col对应K和M\n",
    "                    int row = index.get_global_id(0);\n",
    "                    int col = index.get_global_id(1);\n",
    "                    // sum保存每个行之和，Xmax保存每行的最大值\n",
    "                    float sum = 0.0f;\n",
    "                    float Xmax = 0.f;\n",
    "                    // 遍历每行得到Xmax\n",
    "                    for (int i = 0; i < N; ++i) {\n",
    "                        Xmax = std::max(Xmax, X[row * M * N + col * N + i]);\n",
    "                    }\n",
    "                    // 遍历每行得到sum\n",
    "                    for (int i = 0; i < N; ++i) {\n",
    "                        sum += exp(X[row * M * N + col * N + i] - Xmax);\n",
    "                    }\n",
    "                    // 遍历每行计算得到三维矩阵Y\n",
    "                    for (int i = 0; i < N; ++i) {\n",
    "                        Y[row * M * N + col * N + i] = X[row * M * N + col * N + i] - Xmax - log(sum);\n",
    "                    }\n",
    "                });\n",
    "    });\n",
    "    e.wait();\n",
    "\n",
    "\n",
    "    // row和col对应K和N\n",
    "    grid_rows = (K + blockSize - 1) / blockSize * blockSize;\n",
    "    grid_cols = (N + blockSize - 1) / blockSize * blockSize;\n",
    "    locXl_ndrange = range<2>(blockSize, blockSize);\n",
    "    global_ndrange = range<2>(grid_rows, grid_cols);\n",
    "\n",
    "    e = q.submit([&](sycl::handler &h) {\n",
    "        h.parallel_for<class T3>(\n",
    "                sycl::nd_range<2>(global_ndrange, locXl_ndrange), [=](sycl::nd_item<2> index) {\n",
    "                    int row = index.get_global_id(0);\n",
    "                    int col = index.get_global_id(1);\n",
    "                    // 计算出最终结果loss\n",
    "                    loss[row * N + col] = -Y[row * N * M + mask[row * N + col] * N + col] * weight[row * N + col];\n",
    "                });\n",
    "    });\n",
    "    e.wait();\n",
    "\n",
    "    // 计算时间\n",
    "    duration += (e.get_profiling_info<info::event_profiling::command_end>() -\n",
    "                 e.get_profiling_info<info::event_profiling::command_start>()) / 1000.0f / 1000.0f;\n",
    "\n",
    "\n",
    "    return (duration);\n",
    "}\n",
    "\n",
    "// CPU计算\n",
    "double cpu_kernel(float *cX, float *closs, int *mask, float *weight, int M, int N, int K) {\n",
    "\n",
    "    double duration = 0.0;\n",
    "    std::chrono::high_resolution_clock::time_point s, e;\n",
    "\n",
    "    s = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    // 用Y记录中间的变量结果，sum用于记录X的每一个行的总和\n",
    "    float *Y = new float[K * M * N]();\n",
    "\n",
    "    for (int i = 0; i < K; i++) {\n",
    "        // 求Xmax和sum\n",
    "        for (int j = 0; j < M; j++) {\n",
    "            float Xmax = 0.f;\n",
    "            for (int k = 0; k < N; ++k) {\n",
    "                Xmax = std::max(Xmax, cX[i * M * N + j * N + k]);\n",
    "            }\n",
    "            float sum1 = 0.0f;\n",
    "            for (int k = 0; k < N; k++) {\n",
    "                sum1 += exp(cX[i * M * N + j * N + k] - Xmax);\n",
    "            }\n",
    "            // 求Y\n",
    "            for (int k = 0; k < N; ++k) {\n",
    "                Y[i * M * N + j * N + k] = cX[i * M * N + j * N + k] - Xmax - log(sum1);\n",
    "                // cout << \"CPU Y: k = \" << i << \"m = \" << j << \" n = \" << k<< \" value = \"<< Y[j*N + k] << endl;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // 计算出loss结果\n",
    "        for (int j = 0; j < N; ++j) {\n",
    "            // closs[K][N]和weight[K][N]的下标变换为i*N+j, Y[M][N]下标变换为(mask[i*N+J])*N + j\n",
    "            closs[i * N + j] = -Y[i * M * N + mask[i * N + j] * N + j] * weight[i * N + j];\n",
    "        }\n",
    "    }\n",
    "    e = std::chrono::high_resolution_clock::now();\n",
    "    duration = std::chrono::duration<float, std::milli>(e - s).count();\n",
    "\n",
    "    return (duration);\n",
    "}\n",
    "\n",
    "int verify(float *cpu_res, float *gpu_res, int length) {\n",
    "    int err = 0;\n",
    "    for (int i = 0; i < length; i++) {\n",
    "        if (fabs(cpu_res[i] - gpu_res[i]) > 0.001) {\n",
    "            err++;\n",
    "            printf(\"\\n%lf, %lf\", cpu_res[i], gpu_res[i]);\n",
    "        }\n",
    "    }\n",
    "    return (err);\n",
    "}\n",
    "\n",
    "// 结果比较\n",
    "int gemm(const int M,\n",
    "         const int N,\n",
    "         const int K,\n",
    "         const int blockSize,\n",
    "         const int iterations,\n",
    "         sycl::queue &q) {\n",
    "    cout << \"Problem size: ｘ(\" << K << \",\" << M << \",\" << N << \")\\n\";\n",
    "    cout << \"Block Size = \" << blockSize << std::endl;\n",
    "    // 将X展开为一维\n",
    "    auto A = malloc_shared<float>(M * K * N, q);\n",
    "    //    TODO:下面定义sumA用于并行计算X的K个矩阵的每行的元素之和\n",
    "    auto sumA = malloc_shared<float>(K * M, q);\n",
    "    auto Y = malloc_shared<float>(M * K * N, q);\n",
    "\n",
    "    // mask、weight和loss都为K*N大小，展开为一维\n",
    "    const int size2 = K * N;\n",
    "    auto mask = malloc_shared<int>(size2, q);\n",
    "    auto weight = malloc_shared<float>(size2, q);\n",
    "\n",
    "    // 下面的Ｃ和C_host用于保存GPU和CPU的运行结果loss\n",
    "    auto C = malloc_shared<float>(K * N, q);\n",
    "    auto C_host = malloc_host<float>(K * N, q);\n",
    "\n",
    "    // 初始化\n",
    "    for (int i = 0; i < M * K * N; i++) {\n",
    "        A[i] = random_float();\n",
    "        Y[i] = 0.f;\n",
    "    }\n",
    "\n",
    "    for (int i = 0; i < K * M; i++) {\n",
    "        sumA[i] = 0;\n",
    "    }\n",
    "\n",
    "    for (int i = 0; i < N * K; i++) {\n",
    "        mask[i] = random_int(M);\n",
    "        weight[i] = random_float();\n",
    "        C[i] = 0.0f;\n",
    "        C_host[i] = 0.0f;\n",
    "    }\n",
    "\n",
    "    // 保存每秒浮点计算的数值，这个为Ａ和B两个矩阵的数据总量的２倍\n",
    "    double flopsPerMatrixMul\n",
    "            = 2.0 * static_cXst<double>(M) * static_cXst<double>(N) * static_cXst<double>(K);\n",
    "\n",
    "    double duration_gpu = 0.0f;\n",
    "    double duration_cpu = 0.0f;\n",
    "\n",
    "    // 下面的warmup用于GPU运行次数热身。只有运行次数超过改热身次数后才累加上GPU的run时间\n",
    "    int warmup = 10;\n",
    "    for (int run = 0; run < iterations + warmup; run++) {\n",
    "        float duration = gpu_kernel(A, C, sumA, Y, mask, weight, M, N, K, blockSize, q);\n",
    "        if (run >= warmup) duration_gpu += duration;\n",
    "    }\n",
    "    duration_gpu = duration_gpu / iterations;\n",
    "\n",
    "    // 下面的warmup用于CPU运行次数热身。只有运行次数超过改热身次数后才累加上CPU的run时间\n",
    "    warmup = 2;\n",
    "    for (int run = 0; run < iterations / 2 + warmup; run++) {\n",
    "        float duration = cpu_kernel(A, C_host, mask, weight, M, N, K);\n",
    "        if (run >= warmup) duration_cpu += duration;\n",
    "    }\n",
    "    duration_cpu = duration_cpu / iterations / 2;\n",
    "\n",
    "    // 比较GPU和CPU结果\n",
    "    int errCode = 0;\n",
    "    errCode = verify(C_host, C, N * K);\n",
    "    if (errCode > 0) printf(\"\\nThere are %d errors\\n\", errCode);\n",
    "\n",
    "    printf(\"\\nPerformance Flops = %lf, \\n\"\n",
    "           \"GPU Computation Time = %lf (ms); \\n\"\n",
    "           \"CPU Computaiton Time = %lf (ms); \\n\",\n",
    "           flopsPerMatrixMul, duration_gpu, duration_cpu);\n",
    "\n",
    "    // 释放空间\n",
    "    free(A, q);\n",
    "    free(sumA, q);\n",
    "    free(Y, q);\n",
    "    free(C, q);\n",
    "    free(C_host, q);\n",
    "\n",
    "    return (errCode);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "\n",
    "    auto propList = cl::sycl::property_list{cl::sycl::property::queue::enable_profiling()};\n",
    "    queue my_gpu_queue(cl::sycl::gpu_selector{}, propList);\n",
    "\n",
    "\n",
    "    int K = 128, M = 32, N = 8192;\n",
    "    int block = 8;\n",
    "    int errCode = gemm(M, N, K, block, 3, my_gpu_queue);\n",
    "\n",
    "    return (errCode);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_simple-vector-incr.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_simple-vector-incr.sh; else ./run_simple-vector-incr.sh; fi"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
